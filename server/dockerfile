# Use the official Golang image to create a build artifact.
FROM golang:1.17-alpine as builder

# Set the Current Working Directory inside the container
WORKDIR /app

# Copy go mod and sum files
COPY go.mod go.sum ./

# Download all dependencies. Dependencies will be cached if the go.mod and go.sum files are not changed
RUN go mod download

# Copy the source code into the container
COPY . .

# Build the Go app
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o catgpt-backend ./cmd/catgpt-backend/

# Start a new stage from scratch
FROM alpine:latest

RUN apk --no-cache add ca-certificates
RUN apk add --no-cache curl

# Set the Current Working Directory inside the container
WORKDIR /root/

# Install Ollama
RUN curl -fsSL https://ollama.com/install.sh | sh

# Download LLaMA3 model
RUN ollama download llama3

# Copy the Pre-built binary file from the previous stage
COPY --from=builder /app/catgpt-backend .

# Expose ports
EXPOSE 8080
EXPOSE 11434
#  As usual the Ollama api will be served on http://localhost:11434.

# Start Ollama and the backend
CMD ollama start llama3 --port 1144 & ./catgpt-backend
